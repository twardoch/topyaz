This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: varia, .specstory, AGENT.md, CLAUDE.md, PLAN.md, llms.txt, .cursorrules
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    push.yml
    release.yml
src/
  topyaz/
    topyaz.py
tests/
  test_package.py
.cursorindexingignore
.gitignore
.pre-commit-config.yaml
cleanup.sh
LICENSE
package.toml
pyproject.toml
README.md
SPEC.md
TODO.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".cursorindexingignore">
# Don't index SpecStory auto-save files, but allow explicit context inclusion via @ references
.specstory/**
</file>

<file path="cleanup.sh">
#!/usr/bin/env bash

python -m uzpy run -e src
fd -e py -x autoflake {}
fd -e py -x pyupgrade --py311-plus {}
fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}
fd -e py -x ruff format --respect-gitignore --target-version py311 {}
repomix -i varia,.specstory,AGENT.md,CLAUDE.md,PLAN.md,llms.txt,.cursorrules -o llms.txt .
python -m pytest
</file>

<file path="SPEC.md">
# topyaz: Unified Python CLI Wrapper for Topaz Labs Products

## Overview

`topyaz` is a comprehensive Python package that provides a unified command-line interface for Topaz Labs' three flagship products: Video AI, Gigapixel AI, and Photo AI. The package serves as an intelligent wrapper around the native CLI tools provided by Topaz Labs, offering both local and remote execution capabilities via SSH. The tool is designed to be robust, user-friendly, and production-ready for batch processing workflows.

## Architecture and Design Philosophy

### Core Design Principles

1. **Unified Interface**: A single Python class with consistent CLI options across all three Topaz products
2. **Remote Execution Support**: Native SSH and macOS remote execution capabilities
3. **Failsafe Operation**: Comprehensive error handling, validation, and recovery mechanisms
4. **Detailed Feedback**: Verbose logging and progress reporting for all operations
5. **Production Ready**: Designed for automated workflows and batch processing

### Implementation Strategy

The package implements a unified class structure using Python Fire for automatic CLI generation. The main class `topyazWrapper` serves as the entry point, with specialized methods for each Topaz product (`photo`, `video`, `gp` for Gigapixel). The design emphasizes parameter consistency while accommodating product-specific requirements.

## Class Structure and Implementation

### Main Class: topyazWrapper

```python
class topyazWrapper:
    def __init__(self, 
                 remote_host: str = None,
                 ssh_user: str = None, 
                 ssh_key: str = None,
                 verbose: bool = True,
                 dry_run: bool = False,
                 log_level: str = "INFO",
                 timeout: int = 3600,
                 parallel_jobs: int = 1,
                 output_dir: str = None,
                 preserve_structure: bool = True,
                 backup_originals: bool = False):
        """
        Initialize the topyaz wrapper with unified options.
        
        Args:
            remote_host: Remote machine hostname/IP for SSH execution
            ssh_user: SSH username for remote execution
            ssh_key: Path to SSH private key file
            verbose: Enable detailed output and progress reporting
            dry_run: Show commands without executing them
            log_level: Logging level (DEBUG, INFO, WARNING, ERROR)
            timeout: Maximum execution time in seconds per operation
            parallel_jobs: Number of concurrent operations (where supported)
            output_dir: Default output directory for processed files
            preserve_structure: Maintain input directory structure in output
            backup_originals: Create backup copies before processing
        """
```

### Product-Specific Methods

#### Video AI Method
```python
def video(self,
          input_path: str,
          model: str = "amq-13",
          scale: int = 2,
          fps: int = None,
          codec: str = "hevc_videotoolbox",
          quality: int = 18,
          denoise: int = None,
          details: int = None,
          halo: int = None,
          blur: int = None,
          compression: int = None,
          stabilize: bool = False,
          interpolate: bool = False,
          custom_filters: str = None,
          device: int = 0,
          **kwargs) -> bool:
    """
    Process videos using Topaz Video AI.
    
    Supports all major Video AI models and parameters including:
    - Artemis models: amq-13, ahq-10/11/12, alq-10/12/13, alqs-1/2, amqs-1/2, aaa-9/10
    - Proteus models: prob-2, prap-2
    - Dione models: ddv-1/2/3, dtd-1/3/4, dtds-1/2, dtv-1/3/4, dtvs-1/2
    - Gaia models: gcg-5, ghq-5
    - Theia models: thd-3, thf-4
    - Interpolation models: chr-1/2, chf-1/2/3, apo-8, apf-1
    - Stabilization workflow: cpe-1/2 (analysis) + ref-2 (correction)
    
    Environment variables automatically set:
    - TVAI_MODEL_DATA_DIR: ~/Library/Application Support/Topaz Labs LLC/Topaz Video AI/
    - TVAI_MODEL_DIR: /Applications/Topaz Video AI.app/Contents/Resources/models/
    """
```

#### Gigapixel AI Method
```python
def gp(self,
       input_path: str,
       model: str = "std",
       scale: int = 2,
       denoise: int = None,
       sharpen: int = None,
       compression: int = None,
       detail: int = None,
       creativity: int = None,
       texture: int = None,
       prompt: str = None,
       face_recovery: int = None,
       face_recovery_version: int = 2,
       format: str = "preserve",
       quality: int = 95,
       bit_depth: int = 0,
       parallel_read: int = 1,
       **kwargs) -> bool:
    """
    Process images using Topaz Gigapixel AI.
    
    Supports all Gigapixel AI models:
    - Standard models: "std", "standard"
    - High Fidelity: "hf", "high fidelity", "fidelity"
    - Low Resolution: "low", "lowres", "low resolution", "low res"
    - Art & CG: "art", "cg", "cgi"
    - Lines: "lines", "compression"
    - Very Compressed: "very compressed", "high compression", "vc"
    - Text & Shapes: "text", "txt", "text refine"
    - Recovery models: "recovery" (with --mv 1 or 2 for version)
    - Redefine generative: "redefine" (with prompts, creativity, texture)
    
    Face Recovery options:
    - --face-recovery-version: 1 or 2 (default 2)
    - --face-recovery-creativity: 0 (realistic) or 1 (creative)
    
    CLI executable paths:
    - Primary: /Applications/Topaz Gigapixel AI.app/Contents/MacOS/gigapixel
    - Alternative: /Applications/Topaz Gigapixel AI.app/Contents/Resources/bin/gpai
    
    Note: CLI functionality requires Gigapixel AI Pro license ($499/year)
    Performance: CLI is ~2x faster than GUI for batch operations
    """
```

#### Photo AI Method
```python
def photo(self,
          input_path: str,
          autopilot_preset: str = "default",
          format: str = "preserve",
          quality: int = 95,
          compression: int = 2,
          bit_depth: int = 16,
          tiff_compression: str = "zip",
          show_settings: bool = False,
          skip_processing: bool = False,
          override_autopilot: bool = False,
          upscale: bool = None,
          noise: bool = None,
          sharpen: bool = None,
          lighting: bool = None,
          color: bool = None,
          **kwargs) -> bool:
    """
    Process images using Topaz Photo AI.
    
    Photo AI operates primarily through Autopilot settings configured in the GUI.
    Limited CLI parameter control available, with most processing decisions 
    made by the Autopilot system based on image analysis.
    
    CLI executable paths:
    - Primary: /Applications/Topaz Photo AI.app/Contents/MacOS/Topaz Photo AI
    - Alternative: /Applications/Topaz Photo AI.app/Contents/Resources/bin/tpai
    
    Return codes:
    - 0: Success
    - 1: Partial Success (some files failed)
    - -1 (255): No valid files passed
    - -2 (254): Invalid log token (requires GUI login)
    - -3 (253): Invalid argument
    
    Experimental settings override (subject to change):
    - --override: Replace Autopilot settings completely
    - --upscale enabled=true/false: Toggle upscale enhancement
    - --noise enabled=true/false: Toggle denoise enhancement
    - --sharpen enabled=true/false: Toggle sharpen enhancement
    - --lighting enabled=true/false: Toggle lighting adjustment
    - --color enabled=true/false: Toggle color balance
    
    Note: Batch processing limit ~450 images per run
    """
```

## Feature Implementation Details

### Remote Execution Architecture

The remote execution system supports both traditional SSH and native macOS mechanisms for running Topaz tools on remote machines. This is particularly valuable for offloading processing to more powerful machines or distributed processing workflows.

#### SSH Implementation
```python
def _execute_remote_ssh(self, command: str, host: str, user: str, key_path: str = None) -> tuple:
    """
    Execute command on remote host via SSH.
    
    Features:
    - Automatic SSH key authentication
    - Connection pooling and reuse
    - Secure file transfer capabilities
    - Remote environment variable setup
    - Progress monitoring over SSH
    """
```

#### macOS Native Remote Execution
```python
def _execute_remote_macos(self, command: str, host: str, user: str) -> tuple:
    """
    Execute command on remote macOS host using native mechanisms.
    
    Utilizes macOS-specific features:
    - Screen Sharing integration
    - Remote Desktop protocols
    - Keychain integration for authentication
    - Native file sharing protocols (AFP/SMB)
    """
```

### Input Validation and Error Handling

The package implements comprehensive validation for all input parameters, file paths, and system requirements. Error handling covers common issues identified in the research:

#### Authentication Validation
```python
def _validate_authentication(self, product: str) -> bool:
    """
    Verify Topaz product authentication status.
    
    Checks:
    - License file existence and validity
    - Pro license requirements for Gigapixel AI CLI
    - Authentication token expiration
    - GUI login requirement detection
    """
```

#### Environment Validation
```python
def _validate_environment(self, product: str) -> bool:
    """
    Validate system environment for Topaz products.
    
    Validates:
    - macOS version compatibility
    - Required environment variables
    - Model file availability
    - Disk space requirements (~80GB for Video AI)
    - Memory and GPU requirements
    """
```

#### File and Path Validation
```python
def _validate_paths(self, input_path: str, output_path: str = None) -> tuple:
    """
    Comprehensive path validation and sanitization.
    
    Handles:
    - Path expansion and normalization
    - Permission checks for read/write access
    - Space character handling in paths
    - Recursive directory validation
    - Output directory creation with --create-folder equivalent
    """
```

### Progress Monitoring and Logging

The package provides detailed progress monitoring and logging capabilities, essential for long-running batch operations.

#### Progress Tracking
```python
class ProgressMonitor:
    """
    Advanced progress monitoring for batch operations.
    
    Features:
    - Real-time progress estimation
    - ETA calculation based on processing speed
    - Memory usage monitoring
    - GPU utilization tracking
    - Batch completion statistics
    """
    
    def track_video_processing(self, ffmpeg_output: str) -> dict:
        """Parse FFmpeg output for Video AI progress."""
        
    def track_image_processing(self, cli_output: str, total_files: int) -> dict:
        """Parse CLI output for Gigapixel/Photo AI progress."""
```

#### Logging System
```python
def _setup_logging(self, log_level: str, log_file: str = None) -> None:
    """
    Configure comprehensive logging system.
    
    Provides:
    - Structured logging with timestamps
    - Different log levels for various components
    - File and console output options
    - JSON-formatted logs for automation integration
    - Error aggregation and reporting
    """
```

## Command Line Interface Design

The CLI design emphasizes usability and consistency across all three Topaz products while accommodating their unique requirements.

### Basic Usage Examples

#### Video Processing
```bash
# Basic 2x upscaling with default settings
topyaz video input.mp4 --scale 2

# Advanced processing with multiple enhancements
topyaz video input.mp4 \
    --model amq-13 \
    --scale 2 \
    --interpolate \
    --fps 60 \
    --denoise 50 \
    --stabilize \
    --output-dir ./enhanced

# Remote processing on powerful machine
topyaz video input.mp4 \
    --remote-host gpu-server.local \
    --ssh-user admin \
    --scale 4 \
    --model prob-3
```

#### Image Processing with Gigapixel AI
```bash
# Batch upscaling with Pro license
topyaz gp photos/ \
    --scale 4 \
    --model recovery \
    --denoise 40 \
    --sharpen 20 \
    --face-recovery 80 \
    --parallel-read 4

# Generative upscaling with prompt
topyaz gp low_res_art/ \
    --model redefine \
    --scale 2 \
    --creativity 4 \
    --texture 3 \
    --prompt "high resolution digital artwork"
```

#### Photo AI Batch Processing
```bash
# Autopilot-based enhancement
topyaz photo raw_photos/ \
    --format jpg \
    --quality 95 \
    --show-settings

# Remote batch processing
topyaz photo photos/ \
    --remote-host photo-server \
    --format tiff \
    --bit-depth 16 \
    --preserve-structure
```

### Advanced Workflow Examples

#### Multi-Stage Processing Pipeline
```bash
# Process video: stabilize -> upscale -> interpolate
topyaz video shaky_video.mp4 \
    --stabilize \
    --model amq-13 \
    --scale 2 \
    --interpolate \
    --fps 60 \
    --backup-originals
```

#### Distributed Processing
```bash
# Split large batch across multiple machines
topyaz gp large_photo_collection/ \
    --remote-host server1,server2,server3 \
    --parallel-jobs 3 \
    --scale 2 \
    --load-balance
```

## Configuration and Settings Management

### Configuration File Support
The package supports configuration files for storing commonly used settings and remote connection details.

```yaml
# ~/.topyaz/config.yaml
defaults:
  output_dir: "~/processed"
  preserve_structure: true
  backup_originals: false
  log_level: "INFO"

video:
  default_model: "amq-13"
  default_codec: "hevc_videotoolbox"
  default_quality: 18

gigapixel:
  default_model: "std"
  default_format: "preserve"
  parallel_read: 4

photo:
  default_format: "jpg"
  default_quality: 95

remote_hosts:
  gpu-server:
    host: "192.168.1.100"
    user: "admin"
    key: "~/.ssh/topaz_key"
  render-farm:
    host: "render.local"
    user: "processor"
    key: "~/.ssh/render_key"
```

### Environment Variable Support
```bash
# Environment variables for common settings
export topyaz_DEFAULT_OUTPUT="~/processed"
export topyaz_REMOTE_HOST="gpu-server.local"
export topyaz_LOG_LEVEL="DEBUG"
export topyaz_BACKUP_ORIGINALS="true"
```

## Error Handling and Recovery

### Comprehensive Error Detection
The package implements robust error detection for common issues identified in the research:

1. **Authentication Failures**: Automatic detection and user guidance for re-authentication
   - Video AI: Check for valid auth.tpz file
   - Photo AI: Detect exit code -2 (254) for invalid log token
   - Gigapixel AI: Verify Pro license activation

2. **Memory Constraints**: Automatic batch size adjustment and memory monitoring
   - Video AI: CUDA out of memory error handling with instances parameter reduction
   - Photo AI: Batch size limitation detection (~450 images max)
   - Gigapixel AI: Parallel read optimization based on 8GB memory cap

3. **GPU Errors**: Fallback to CPU processing and device selection
   - "No such filter: 'tvai_up'" error handling (wrong FFmpeg binary)
   - Device selection for multi-GPU systems
   - VideoToolbox vs. software encoding fallback

4. **Path Issues**: Intelligent path handling with space character support
   - Automatic path quoting for spaces in filenames
   - macOS application bundle access permission handling
   - Write permission validation for output directories

5. **Model Download Failures**: Retry mechanisms and fallback strategies
   - TVAI_MODEL_DATA_DIR write permission issues
   - Symbolic link creation for restricted app bundle access
   - 80GB space requirement validation

6. **Network Issues**: Connection retry and timeout handling for remote operations
   - SSH connection pooling and reuse
   - Remote environment variable setup validation
   - Network diagnostic tools for remote hosts

### Recovery Mechanisms
```python
def _handle_processing_error(self, error: Exception, context: dict) -> bool:
    """
    Intelligent error handling with recovery attempts.
    
    Recovery strategies:
    - Reduce batch size for memory errors
    - Retry with different device for GPU errors
    - Fall back to local processing for remote failures
    - Prompt for re-authentication when needed
    - Resume processing from last successful file
    """
```

### Resumable Operations
```python
def _create_checkpoint(self, operation_id: str, state: dict) -> None:
    """
    Create operation checkpoint for resumable processing.
    
    Enables:
    - Resume interrupted batch operations
    - Skip already processed files
    - Maintain processing statistics
    - Recovery from system crashes
    """
```

## Performance Optimization

### Parallel Processing Support
The package implements intelligent parallel processing that respects the limitations of each Topaz product:

- **Video AI**: Sequential processing with optimal FFmpeg parameters
- **Gigapixel AI**: Parallel image loading with memory constraints
- **Photo AI**: Batch size optimization based on available memory

### Hardware Detection and Optimization
```python
def _detect_hardware_capabilities(self) -> dict:
    """
    Detect and optimize for available hardware.
    
    Detects:
    - Apple Silicon vs Intel architecture
    - Available GPU memory and capabilities
    - CPU core count and memory
    - Storage speed and available space
    - Network capabilities for remote processing
    """
```

### Memory Management
```python
def _optimize_memory_usage(self, file_list: list, available_memory: int) -> list:
    """
    Optimize batch processing based on available memory.
    
    Implements:
    - Dynamic batch size calculation
    - Memory usage prediction
    - Garbage collection optimization
    - Process memory monitoring
    """
```

## Testing and Validation

### Unit Test Coverage
The package includes comprehensive unit tests covering:

- All CLI parameter combinations
- Error handling scenarios
- Remote execution functionality
- File handling and validation
- Progress monitoring accuracy

### Integration Tests
```python
def test_video_ai_integration():
    """Test complete Video AI workflow with real files."""
    
def test_gigapixel_pro_features():
    """Test Gigapixel AI Pro-specific functionality."""
    
def test_remote_execution():
    """Test SSH and remote execution capabilities."""
    
def test_batch_processing():
    """Test large batch operations with various file types."""
```

### Validation Scripts
```bash
# Validation script for system requirements
topyaz validate --check-licenses --check-environment --check-connectivity

# Performance benchmarking
topyaz benchmark --test-local --test-remote --generate-report
```

## Documentation and User Guidance

### Comprehensive Help System
The package provides extensive help documentation accessible via CLI:

```bash
# General help
topyaz --help

# Product-specific help
topyaz video --help
topyaz gp --help
topyaz photo --help

# Show examples and tutorials
topyaz examples
topyaz tutorial video
topyaz troubleshoot
```

### Interactive Setup Wizard
```bash
# Initial setup and configuration
topyaz setup --interactive

# Remote host configuration
topyaz setup --add-remote-host

# License and authentication verification
topyaz setup --verify-licenses
```

## Installation and Dependencies

### Package Requirements
```python
# setup.py dependencies
install_requires = [
    "fire>=0.4.0",           # CLI framework
    "paramiko>=2.7.0",       # SSH functionality
    "pyyaml>=5.4.0",         # Configuration files
    "tqdm>=4.60.0",          # Progress bars
    "psutil>=5.8.0",         # System monitoring
    "pathlib>=1.0.0",        # Path handling
    "typing-extensions>=3.7.0",  # Type hints
]
```

### Installation Methods
```bash
# PyPI installation
pip install topyaz

# Development installation
git clone https://github.com/user/topyaz.git
cd topyaz
pip install -e .

# Conda installation
conda install -c conda-forge topyaz
```

### System Requirements
- macOS 11.0 Big Sur or higher (Video AI requires 10.14 Mojave minimum for CPU, 10.16 Big Sur for GPU)
- macOS 13 Ventura or newer for advanced models (Rhea, Aion, Iris Enhancement)
- macOS 14 Sonoma for Gigapixel AI generative models (Recover, Redefine)
- Python 3.8 or higher
- Topaz Video AI, Gigapixel AI, and/or Photo AI installed
- Valid licenses for respective products (Pro license required for Gigapixel AI CLI - $499/year)
- Minimum 16GB RAM (32GB recommended for 4K video processing)
- Apple Silicon: 8GB unified memory minimum, Intel: 16GB system RAM
- 80GB+ free disk space for Video AI models
- 2GB+ VRAM for GPU acceleration

## Security Considerations

### SSH Security
- Support for SSH key-based authentication only
- No password storage or transmission
- SSH connection validation and host key verification
- Secure file transfer protocols

### File Security
- Input validation to prevent path traversal attacks
- Safe temporary file handling
- Backup verification and integrity checks
- Secure cleanup of temporary files

### Remote Execution Security
- Command injection prevention
- Environment variable sanitization
- Restricted command execution scope
- Audit logging for all remote operations

## Community Tools Integration

### Existing Community Projects
The package integrates with and references existing community tools:

1. **vai-docker**: Docker containerization for Video AI on Linux
   - GitHub: https://github.com/jojje/vai-docker
   - Enables cross-platform Video AI usage
   - GPU acceleration support within containers

2. **gigapixel-automator**: AppleScript automation for pre-CLI Gigapixel versions
   - GitHub: https://github.com/halfSpinDoctor/gigapixel-automator
   - Legacy GUI automation (now superseded by native CLI)
   - Compatible with older Gigapixel versions

3. **ComfyUI-TopazVideoAI**: Video AI integration for ComfyUI
   - GitHub: https://github.com/sh570655308/ComfyUI-TopazVideoAI
   - Node-based workflow integration
   - Custom filter pipeline support

4. **Python Gigapixel Package**: PyPI wrapper for Gigapixel AI
   - Programmatic control interface
   - Version compatibility requirements
   - Integration patterns for automation

### Integration Capabilities
```python
def integrate_community_tools(self):
    """
    Detect and integrate with community tools.
    
    Features:
    - Auto-detect vai-docker installations
    - Import existing automation scripts
    - ComfyUI workflow compatibility
    - Legacy script migration assistance
    """
```

## Future Enhancements

### Planned Features
1. **GUI Integration**: Optional web-based monitoring interface
2. **Cloud Processing**: Integration with cloud GPU services (AWS, GCP, Azure)
3. **Plugin System**: Extensible architecture for custom processing workflows
4. **API Server**: REST API for integration with other applications
5. **Distributed Processing**: Native distributed computing support across multiple machines
6. **Machine Learning**: Intelligent parameter optimization based on content analysis
7. **Docker Support**: Native containerization for cross-platform deployment
8. **Workflow Designer**: Visual pipeline designer for complex processing chains

### Community Integration
- GitHub repository with issue tracking and feature requests
- Community-contributed presets and workflows repository
- Plugin marketplace for extensions and custom integrations
- Documentation contributions and example workflows
- Community model and parameter sharing
- Integration with existing Topaz community forums and resources

## Support and Troubleshooting

### Built-in Diagnostics
```bash
# System diagnostic report
topyaz diagnose --full-report

# Performance analysis
topyaz profile --operation video --input sample.mp4

# License verification
topyaz license-check --all-products
```

### Common Issue Resolution
The package includes automated detection and resolution guidance for common issues:

1. **"No such filter" errors**: Automatic Topaz FFmpeg detection
2. **Authentication failures**: Step-by-step re-authentication guidance
3. **Memory errors**: Automatic batch size reduction suggestions
4. **Permission errors**: Path and permission troubleshooting
5. **Remote connection issues**: Network diagnostic and troubleshooting tools

This specification provides a comprehensive foundation for implementing `topyaz` as a production-ready, user-friendly wrapper around Topaz Labs CLI tools, with extensive error handling, remote execution capabilities, and detailed user feedback throughout all operations.

# Appendix: Reference for Topaz CLI tools

## Topaz Gigapixel AI

Topaz Gigapixel AI in CLI operates via its `gigapixel` CLI tool. 

```
gpai="/Applications/Topaz Gigapixel AI.app/Contents/Resources/bin/gpai"
"${gpai}" --help

usage: Topaz Gigapixel AI [-v] [--cli] [-m MODEL] [--mv VERSION] 
       [--dn STRENGTH] [--sh STRENGTH] [--cm STRENGTH] [--dt STRENGTH] 
       [--cr STRENGTH] [--tx STRENGTH] [--prompt STR] [--pds FACTOR] 
       [--fr STRENGTH] [--frv VERSION] [--frc CREATIVITY] [--gc] 
       [--scale MULTIPLIER] [--width PIXELS] [--height PIXELS] 
       [--res RESOLUTION] [-i PATH [PATH ...]] [-r] [-o PATH] [--cf] 
       [--prefix STR] [--suffix STR] [--am] [--overwrite] [--se] [--flatten] 
       [-f {preserve, jpg, jpeg, png, tif, tiff}] [--tc {none, zip, lzw}] 
       [--pc LEVEL] [--bd {0, 8, 16}] [--jq QUALITY] 
       [--cs {preserve, prophoto, srgb, adobe, apple, wide, cmyk}] [--icc PATH] 
       [--verbose] [-q] [-p QUANTITY] [-d DEVICE] [--ld] [-h]

High quality image upscaler

arguments:
  -v, --version     Show version information.
  --cli             Force application to run in CLI mode.
  -m MODEL, --model MODEL
                    Model used to process images.
  --mv VERSION, --model-version VERSION
                    Version number of the model being used.
  --dn STRENGTH, --denoise STRENGTH
                    How much denoising to apply. Only applies to models that use 
                    the denoise parameter.
  --sh STRENGTH, --sharpen STRENGTH
                    How much sharpening to apply. Only applies to models that 
                    use the sharpen parameter.
  --cm STRENGTH, --compression STRENGTH
                    How much compression reduction to apply. Only applies to 
                    models that use the compression parameter.
  --dt STRENGTH, --detail STRENGTH
                    How much detail enhancement to apply. Only applies to models 
                    that use the detail parameter.
  --cr STRENGTH, --creativity STRENGTH
                    How much creativity the model should be allowed to have. 
                    Only applies to models that use the creativity parameter.
  --tx STRENGTH, --texture STRENGTH
                    How much texture the model should be allowed to add. Only 
                    applies to models that use the detail parameter.
  --prompt STR      What prompt to give to the model. Only applies to models 
                    that use the prompt parameter.
  --pds FACTOR, --predownscale FACTOR
                    Pre-downscale factor for Recovery V2. (Default: 100)
  --fr STRENGTH, --face-recovery STRENGTH
                    Face recovery strength.
  --frv VERSION, --face-recovery-version VERSION
                    Version number of the face recovery model being used.
  --frc CREATIVITY, --face-recovery-creativity CREATIVITY
                    Whether to use realistic or creative face recovery. Only 
                    applicable to Face Recovery v2.
  --gc, --gamma-correction
                    Enable gamma correction
  --scale MULTIPLIER
                    Upscale images by a specific multiplier.
  --width PIXELS    Upscale images to a specific width.
  --height PIXELS   Upscale images to a specific height.
  --res RESOLUTION, --resolution RESOLUTION
                    The output resolution to use. Takes values in format #(ppi/
                    ppcm), e.g., 300ppi, 100ppcm.
  -i PATH [PATH ...], --input PATH [PATH ...]
                    File and/or folders to process.
  -r, --recursive   Recurse into sub-folders when parsing input directories.
  -o PATH, --output PATH
                    Folder to save images to. Use --cf to create output folders 
                    automatically.
  --cf, --create-folder
                    Creates the output folder if it doesn't already exist.
  --prefix STR      Prefix to prepend to output filename.
  --suffix STR      Suffix to append to output filename.
  --am, --append-model
                    Append model name used to output filename.
  --overwrite       Overwrite input files with output. THIS IS DESTRUCTIVE.
  --se, --skip-existing
                    Skip files whose output file already exists. Helpful for 
                    resuming a previous run.
  --flatten         If input is recursive, place all files at single level in 
                    output folder.
  -f {preserve, jpg, jpeg, png, tif, tiff}, --image-format {preserve, jpg, jpeg, png, tif, tiff}
                    Image format to save to.
  --tc {none, zip, lzw}, --tiff-compression {none, zip, lzw}
                    Which compression scheme to use for TIFF outputs. (Default: zip)
  --pc LEVEL, --png-compression LEVEL
                    Which compression level to use for PNG outputs. (Default: 4)
  --bd {0, 8, 16}, --bit-depth {0, 8, 16}
                    What bit depth to use for PNG/TIFF outputs. 0 will preserve 
                    input file depth. (Default: 0)
  --jq QUALITY, --jpeg-quality QUALITY
                    What quality level to save JPEG outputs. (Default: 95)
  --cs {preserve, prophoto, srgb, adobe, apple, wide, cmyk}, --colorspace {preserve, prophoto, srgb, adobe, apple, wide, cmyk}
                    What color space to save the output with. (Default: preserve)
  --icc PATH        Save out with a specified ICC profile.
  --verbose         Display more information while processing.
  -q, --quiet       Display no information while processing.
  -p QUANTITY, --parallel QUANTITY
                    Maximum files to queue at once. (Default: 1)
  -d DEVICE, --device DEVICE
                    Which device to use. Use --list-devices / --ld to show 
                    current devices. (Default: -2)
  --ld, --list-devices
                    Print a list of current devices.
  -h, --help        Shows this help message
```


Released in version 7.3.0, Gigapixel's Command Line Interface (CLI) feature, [available exclusively to Pro License users](https://www.topazlabs.com/gigapixel-pro), offers advanced functionality for efficient batch processing and integration into automated workflows. Users can leverage this feature to upscale images with precision and speed directly from the command line, ensuring seamless integration with existing software systems and maximizing productivity.

---

#### Notes

*Updated May 21st, 2025
Command line flags subject to change.*

After install, you should be able to access it from the command line/powershell/terminal by typing in **gigapixel** (or **gigapixel-alpha/gigapixel-beta** depending on release type) as the command.

With no arguments, this should print a usage dialog.

The following examples are written with UNIX-style escape characters. Windows users may need to edit these commands to follow CMD/PowerShell formatting.

---

#### Basics

* -m, --model for model. Valid values are specified in json files but should account for common shortenings (e.g., art, cg, and cgi are valid for Art & CGI model)
  + If there is a short code missing that you tried and it didn't work let us know

**AI Models and their corresponding aliases**

|  |  |
| --- | --- |
| AI Models | Aliases |
| Art & CG | "art", "cg", "cgi" |
| Lines | "lines", "compression" |
| Very Compressed | "very compressed", "high compression", "vc" |
| High Fidelity | "hf", "high fidelity", "fidelity" |
| Low Resolution | "low", "lowres", "low resolution", "low res" |
| Standard | "std", "standard" |
| Text & Shapes | "text", "txt", "text refine" |
| Recover | "recovery" |
| Redefine | "redefine" |

* –mv, --model-version for model version. Valid values are based on the UI model versions, so version 2 is for standard, low res, and high fidelity models
* --dn/--denoise, --sh/--sharpen, --cm/--compression for the various model options. Accepts values 1-100.
* --fr, --face-recovery for both enabling and setting face recovery strength. Accepts values 1-100.
* --scale, --width, --height for setting upscale type/value. All mutually exclusive.
* --res, --resolution for setting pixel density
  + Valid values are stuff like 300ppi, 150ppcm
* -i or --input specifies which files or folders to process.
* -r, --recursive should recurse into subdirectories when finding input files
* -o, --output to specify output folder
* --cf, --create-folder will create the output folder if it doesn't exist
* --prefix adds a prefix to the output file name
* --suffix adds a suffix to the output file name
* --overwrite allows overwriting file **(CANNOT BE UNDONE)**
* --flatten will flatten folder structure if using recursive mode
  + e.g., input/a/1.png and input/b/2.png would be put in output folder without the a/b directories
* -f, --image-format specifies the output file type
  + Accepts jpg, jpeg, tif, tiff, png, and preserve (default)
  + jpg/tif vs jpeg/tiff will allow 3 vs 4 character output extensions for flexibility
* --tc, --tiff-compression sets the tiff compression type
  + Valid values are none, zip (default), and lzw
  + Only used if output type is tiff (either set directly or through preserve)
* --pc, --png-compression sets compression level for png outputs
  + Valid values are 0-9 (default 4)
  + Only used if output type is png (either set directly or through preserve)
* --bd, --bit-depth sets the bit depth of the output
  + Valid values are 0 (default), 8, and 16
  + 0 will preserve input bit depth
* --jq, --jpeg-quality sets output jpeg quality
  + Valid values are 0-100 (default 95)
* --cs, --colorspace sets what color space to use for output
  + Valid values are preserve (default), sRGB, Pro Photo, Apple, Adobe, Wide, and CMYK
* --icc specifies a custom color profile to use for output
  + Overrides --colorspace flag except in the case of CMYK
* --verbose turns on more logging lines
* --q, --quiet turns off all logging (some logs may still leak through though)
* -p, --parallel enables reading multiple files at once to save time at the cost of memory
  + Accepts any positive integer. A value of 1 is identical to normal flow, a value of 10 would load 10 images at once.
  + Note that the parallel reading is capped at 8GB estimate file size (image size + upscaled image size estimate)
* –am, --append-model appends model name and scale to the end of the filename (not implemented yet)
* --face-recovery-creativity, --frc for creativity, 0 or 1

---

#### Generative Models

New models for -m flag: "recovery" and "redefine".
recovery accepts additional --mv flag, either 1 or 2 (default).

**For "recovery"**

* --detail: 1-100, used by recovery
* --face-recovery-version or --frv
* --frv 2 for v2 (default) or --frv 1 for version
* --face-recovery-creativity, --frc for creativity, 0 or 1

**For "redefine"**

* --creativity, --cr: 1-6, redefine only
* --texture, --tx: 1-6, redefine only
* --prompt: Image description to pass to redefine model
* --denoise: 1-6 when used with redefine
* --sharpen: 1-6 when used with redefine

*Example for running Redefine with a prompt*

```
gigapixel.exe -i image.png -o output_folder -m redefine --cr 3 --tx 3 --prompt " This would be where I would put the image prompt if I had one" --am
```

*In more detail*

```
gigapixel.exe        # CLI executable command
    -i image.png     # Input image
    -o output_folder # Output folder/path
    -m redefine      # Model name
    --cr 3           # Creativity value
    --tx 3           # Texture value
    --dn 1           # Denoise value
    --sh 1           # Sharpen value
    --prompt "This would be where I would put the image prompt if I had one" # Prompt value
    --am             # Append model name to output
```

---

#### Examples

The **gigapixel** executable should be on the path by default after install, but if not you can add it to your path. The default paths should be:

**Windows**

```
C:\Program Files\Topaz Labs LLC\Topaz Gigapixel AI\bin

```

**Mac**

```
/Applications/Topaz Gigapixel AI.app/Contents/Resources/bin
```

*Upscale all files in a folder by 2x using auto settings, preserving all aspects of image format (extension, bit depth, etc)*

```
gigapixel --recursive -i ~/Pictures/inputs -o ~/Pictures/outputs --scale 2
```

*Upscale all files inside input directory recursively*

```
gigapixel --recursive -i ~/Pictures/inputs -o ~/Pictures/outputs --scale 2
```

Upscale a single raw and convert it to a jpg without using autopilot (all model parameters are set)

```
gigapixel --recursive -i ~/Pictures/input.cr3 -o ~/Pictures/outputs --scale 2 -m std \
--mv 2 --denoise 30 --sharpen 10 --compression 5 --image-format jpg \
--jpeg-quality 95
```

*Upscale using face recovery set to 80 strength*

```
gigapixel --recursive -i ~/Pictures/input.jpg -o ~/Pictures/outputs --scale 2 --face-recovery 80
```



## Topaz Photo AI

Topaz Photo AI in CLI operates via its `tpai` CLI tool. 

```
tpai='/Applications/Topaz Photo AI.app/Contents/Resources/bin/tpai'; "${tpai}" --help
```

or

```
tpai='/Applications/Topaz Photo AI.app/Contents/MacOS/Topaz Photo AI'; "${tpai}" --cli --help
```
returns:

```
Checking if log directory should be pruned. Currently have 11 log files.
Number of logs exceeds max number to keep ( 10 ). Cleaning excess logs.
Logger initialized
Options:
    --cli: Required to access CLI mode, otherwise images are treated as if passed by an external editor.
    --output, -o: Output folder to save images to. If it doesn't exist the program will attempt to create it.
    --overwrite: Allow overwriting of files. THIS IS DESTRUCTIVE.
    --recursive, -r: If given a folder path, it will recurse into subdirectories instead of just grabbing top level files.
        Note: If output folder is specified, the input folder's structure will be recreated within the output as necessary.
File Format Options:
    --format, -f: Set the output format. Accepts jpg, jpeg, png, tif, tiff, dng, or preserve. Default: preserve
        Note: Preserve will attempt to preserve the exact input extension, but RAW files will still be converted to DNG.
Format Specific Options:
    --quality, -q: JPEG quality for output. Must be between 0 and 100. Default: 95
    --compression, -c: PNG compression amount. Must be between 0 and 10. Default: 2
    --bit-depth, -d: TIFF bit depth. Must be either 8 or 16. Default: 16
    --tiff-compression: -tc: TIFF compression format. Must be "none", "lzw", or "zip".
        Note: lzw is not allowed on 16-bit output and will be converted to zip.
Debug Options:
    --showSettings: Shows the Autopilot settings for images before they are processed
    --skipProcessing: Skips processing the image (e.g., if you just want to know the settings)
    --verbose, -v: Print more log entries to console.
Settings Options:
    Note: EXPERIMENTAL. The API for changing the processing settings is experimental and subject to change.
          After enabling an enhancement you may specify settings to override.
    --showSettings: Prints out the final settings used when processing.
    --override: If specified, any model settings will fully replace Autopilot settings.
                Default behavior will merge other options into Autopilot settings.
    --upscale: Turn on the Upscale enhancement. Pass enabled=false to turn it off instead.
    --noise: Turn on the Denoise enhancement. Pass enabled=false to turn it off instead.
    --sharpen: Turn on the Sharpen enhancement. Pass enabled=false to turn it off instead.
    --lighting: Turn on the Adjust lighting enhancement. Pass enabled=false to turn it off instead.
    --color: Turn on the Balance color enhancement. Pass enabled=false to turn it off instead.

Return values:
    0 - Success
    1 - Partial Success (e.g., some files failed)
    -1 (255) - No valid files passed.
    -2 (254) - Invalid log token. Open the app normally to login.
    -3 (253) - An invalid argument was found.
```

To use the Topaz Photo AI command line interface (CLI), follow the below instructions for your operating system.

Windows Mac

Windows:

1. Open Command Prompt or Terminal
2. Type in:
   cd "C:\Program Files\Topaz Labs LLC\Topaz Photo AI"
3. Type in:
    .\tpai.exe --help
4. Type in:
    .\tpai.exe "folder/or/file/path/here"

![Example Output](https://cdn.sanity.io/images/r2plryeu/production/45fd256fb694c2ff306b5a16b987852a828d10cd-1787x919.png?q=90&fit=max&auto=format)

Mac:

1. Open Terminal
2. Type in:
   cd /Applications/Topaz\ Photo\ AI.app/Contents/MacOS
3. Type in:
   ./Topaz\ Photo\ AI --help
4. Type in:
   ./Topaz\ Photo\ AI --cli "folder/or/file/path/here"

![Example Output](https://cdn.sanity.io/images/r2plryeu/production/79d4022c3676d5b2df9457a354f39ec772ad98dc-1756x936.png?q=90&fit=max&auto=format)

---

## Processing Controls

The CLI will use your Autopilot settings to process images. Open Topaz Photo AI and go to the Preferences > Autopilot menu.

Instructions on using the Preferences > Autopilot menu are [here](https://docs.topazlabs.com/photo-ai/enhancements/autopilot-and-configuration).

### Command Options

--output, -o: Output folder to save images to. If it doesn't exist the program will attempt to create it.

--overwrite: Allow overwriting of files. THIS IS DESTRUCTIVE.

--recursive, -r: If given a folder path, it will recurse into subdirectories instead of just grabbing top level files.
Note: If output folder is specified, the input folder's structure will be recreated within the output as necessary.

### File Format Options:

--format, -f: Set the output format. Accepts jpg, jpeg, png, tif, tiff, dng, or preserve. Default: preserve
Note: Preserve will attempt to preserve the exact input extension, but RAW files will still be converted to DNG.Format Specific Options:

--quality, -q: JPEG quality for output. Must be between 0 and 100. Default: 95

--compression, -c: PNG compression amount. Must be between 0 and 10. Default: 2

--bit-depth, -d: TIFF bit depth. Must be either 8 or 16. Default: 16

--tiff-compression: -tc: TIFF compression format. Must be "none", "lzw", or "zip".
Note: lzw is not allowed on 16-bit output and will be converted to zip.

### Debug Options:

--showSettings: Shows the Autopilot settings for images before they are processed

--skipProcessing: Skips processing the image (e.g., if you just want to know the settings)

--verbose, -v: Print more log entries to console.

Return values:
0 - Success
1 - Partial Success (e.g., some files failed)
-1 (255) - No valid files passed.
-2 (254) - Invalid log token. Open the app normally to login.
-3 (253) - An invalid argument was found.




## Topaz Video AI

Topaz Video AI in CLI operates with help of `ffmpeg`. 


Topaz Video AI supports executing scripts using a command line interface.

This is designed for advanced users comfortable working in such an environment and offers more flexibility in customizing a variety of scripted processes.

We highly recommend using the app’s user interface for those not comfortable working in a command terminal.

The majority of the commands for this build will be FFmpeg commands.

There is no need to install FFmpeg, it is automatically included with the TVAI installer. This article will outline the basic functions for TVAI’s CLI, however, you will want to familiarize yourself with FFmpeg commands for more complex use cases.

### Getting Started with CLI

Before using the CLI for the first time, we recommend launching the GUI and logging into the app. This eliminates the need to use a command to log into the app and will allow you to launch the terminal directly from the GUI.

After logging in, select Process > Open Command Prompt, this will set the model directory automatically. The next time you want to launch the CLI without the GUI, follow the steps below:

Windows macOS

You must manually set the *TVAI\_MODEL\_DATA\_DIR* and *TVAI\_MODEL\_DIR* environment variables if launching without the GUI. Please see the Environment Variables section below.

```
cd "C:\Program Files\Topaz Labs LLC\Topaz Video AI"
```

If you log out and need to log back in without launching the GUI:

```
.\login
```

You must manually set the *TVAI\_MODEL\_DATA\_DIR* and *TVAI\_MODEL\_DIR* environment variables if launching without the GUI. Please see the Environment Variables section below.

```
cd /Applications/Topaz\ Video\ AI.app/Contents/MacOS
```

If you log out and need to log back in without launching the GUI:

```
./login
```

---

### Basic TVAI Filters

Upscaling & Enhancement

```
tvai_up
```

Interpolation

```
tvai_fi
```

Stabilization

```
tvai_cpe + tvai_stb
```

### Video AI Command Line Usage

#### Environment Variables

***TVAI\_MODEL\_DATA\_DIR***

* This variable should be set to the folder where you want model files to be downloaded. A location with ~80 GB of free space will work best.
* Default value:
  + Chosen during initial installation (Windows)
  + /Applications/Topaz Video AI.app/Contents/Resources/models (macOS)

***TVAI\_MODEL\_DIR***

* This variable should be set to the folder containing the model definition files (.json), your authentication file (*auth.tpz*), and the *tvai.tz* file.
* In most cases, this value should not be changed from its default setting.
* Default value:
  + Chosen during initial installation (Windows)
  + /Applications/Topaz Video AI.app/Contents/Resources/models (macOS)

---

### GPU-Specific Usage Notes

TVAI is used as an FFmpeg filter, and all models will work on graphics devices from Intel, AMD, Nvidia, and Apple using a command like this example:

```
-vf "tvai_up=model=aaa-10:scale=2"
```

However, different graphics cards may support different encoders and options. Similarly, different encoders support different options, so you may need to tweak settings on different machines. The following options can be used to take advantage of hardware acceleration features from different GPU manufacturers:

Intel NVIDIA AMD macOS (Intel & Apple Silicon)

On some newer Intel devices, it may be necessary to set the ***`Computer\HKEY\_CURRENT\_USER\Software\Topaz Labs LLC\Topaz Video AI\OVUseDeviceIndex`*** registry entry. You can set the device by adding **`device=#`** to the filter argument, where **#** is the device index:

```
-vf "tvai_up=model=aaa-10:scale=2:device=0"
```

#### General Usage

1. Add the **`-strict 2 -hwaccel auto`** flags
2. Set **`-c:v` to `hevc\_qsv` or `h264\_qsv`**
3. Add **`-profile main -preset medium -max\_frame\_size 65534`**
4. Set **`-global\_quality`** to the desired quality
5. Add **`-pix\_fmt yuv420p -movflags frag\_keyframe+empty\_moov`**
6. Provide **TVAI filter string**

Example Command:

```
./ffmpeg -hide_banner -nostdin -y -strict 2 -hwaccel auto -i "input.mp4" -c:v hevc_qsv -profile main -preset medium -max_frame_size 65534 -global_quality 19 -pix_fmt yuv420p -movflags frag_keyframe+empty_moov -vf "tvai_up=model=amq-13:scale=2:device=0" "output-artemis.mp4"
```

The above command performs the following:

* Hides the FFmpeg startup banner
* Enables hardware acceleration, and uses the hevc\_qsv encoder (H.265)
* Uses the main profile with the medium preset for the encoder
* Sets the CRF to 19
* Sets the output pixel format to yuv420p
* Creates 100% fragmented output, allowing the file to be read if the processing is interrupted
* Upscales 2x using Artemis v13 on GPU #0

1. Add the **`-strict 2 -hwaccel auto`** flags
2. Set **`-c:v` to `hevc\_nvenc` or `h264\_nvenc`**
3. Add **`-profile main -preset medium`**
4. Set **`-global\_quality`**to the desired quality
5. Add **`-pix\_fmt yuv420p -movflags frag\_keyframe+empty\_moov`**
6. Provide **TVAI filter string**

Example Command:

```
./ffmpeg -hide_banner -nostdin -y -strict 2 -hwaccel auto -i "input.mp4" -c:v hevc_nvenc -profile main -preset medium -global_quality 19 -pix_fmt yuv420p -movflags frag_keyframe+empty_moov -vf "tvai_up=model=amq-13:scale=2" "output-artemis.mp4"
```

The above command performs the following:

* Hides the FFmpeg startup banner
* Enables hardware acceleration, and uses the hevc\_nvenc encoder (H.265)
* Uses the main profile with the medium preset for the encoder
* Sets the CRF to 19
* Sets the output pixel format to yuv420p
* Creates 100% fragmented output, allowing the file to be read if the processing is interrupted
* Upscales 2x using Artemis v13

1. Add the **`-strict 2 -hwaccel auto`** flags
2. Set **`-c:v` to `hevc\_amf` or `h264\_amf`**
3. Add **`-profile main`**
4. Set **`-global\_quality`**to the desired quality
5. Add **`-pix\_fmt yuv420p -movflags frag\_keyframe+empty\_moov`**
6. Provide **TVAI filter string**

Example Command:

```
./ffmpeg -hide_banner -nostdin -y -strict 2 -hwaccel auto -i "input.mp4" -c:v hevc_amf -profile main -global_quality 19 -pix_fmt yuv420p -movflags frag_keyframe+empty_moov -vf "tvai_up=model=amq-13:scale=2" "output-artemis.mp4"
```

The above command performs the following:

* Hides the FFmpeg startup banner
* Enables hardware acceleration, and uses the hevc\_amf encoder (H.265)
* Uses the main profile for the encoder
* Sets the CRF to 19
* Sets the output pixel format to yuv420p
* Creates 100% fragmented output, allowing the file to be read if the processing is interrupted
* Upscales 2x using Artemis v13

1. Add the **`-strict 2 -hwaccel auto`** flags
2. Set **`-c:v` to `h264\_videotoolbox` or `hevc\_videotoolbox` or `prores\_videotoolbox`**
3. Add **`-profile main`** for H264 or HEVC outputs, or **`-profile hq`** for ProRes 422 HQ output
4. Set **`-global\_quality`**to the desired quality
5. Add **`-pix\_fmt yuv420p`** for H.264 or HEVC, add **`-pix\_fmt p210le`** for ProRes
6. Provide **TVAI filter string**

Example Command:

```
./ffmpeg -hide_banner -nostdin -y -strict 2 -hwaccel auto -i "input.mp4" -c:v "hevc_videotoolbox" "-profile:v" "main" "-pix_fmt" "yuv420p" "-allow_sw" "1" -vf "tvai_up=model=amq-13:scale=2" "output-artemis.mp4"
```

The above command performs the following:

* Hides the FFmpeg startup banner
* Enables hardware acceleration, and uses the VideoToolbox encoder (H.265)
* Uses the main profile for the encoder
* Sets the output pixel format to yuv420p
* Upscales 2x using Artemis v13

### Selecting Models with CLI

#### Scaling Models

|  |  |
| --- | --- |
| aaa-10 | Artemis Aliased & Moire v10 |
| aaa-9 | Artemis Aliased & Moire v9 |
| ahq-10 | Artemis High Quality v10 |
| ahq-11 | Artemis High Quality v11 |
| ahq-12 | Artemis High Quality v12 |
| alq-10 | Artemis Low Quality v10 |
| alq-12 | Artemis Low Quality v12 |
| alq-13 | Artemis Low Quality v13 |
| alqs-1 | Artemis Strong Dehalo v1 |
| alqs-2 | Artemis Strong Dehalo v2 |
| amq-10 | Artemis Medium Quality v10 |
| amq-12 | Artemis Medium Quality v12 |
| amq-13 | Artemis Medium Quality v13 |
| amqs-1 | Artemis Dehalo v1 |
| amqs-2 | Artemis Dehalo v2 |
| ddv-1 | Dione Interlaced DV v1 |
| ddv-2 | Dione Interlaced DV v2 |
| ddv-3 | Dione Interlaced DV v3 |
| dtd-1 | Dione Interlaced Robust v1 |
| dtd-3 | Dione Interlaced Robust v3 |
| dtd-4 | Dione Interlaced Robust v4 |
| dtds-1 | Dione Interlaced Robust Dehalo v1 |
| dtds-2 | Dione Interlaced Robust Dehalo v2 |
| dtv-1 | Dione Interlaced TV v1 |
| dtv-3 | Dione Interlaced TV v3 |
| dtv-4 | Dione Interlaced TV v4 |
| dtvs-1 | Dione Interlaced Dehalo v1 |
| dtvs-2 | Dione Interlaced Dehalo v2 |
| gcg-5 | Gaia Computer Graphics v5 |
| ghq-5 | Gaia High Quality v5 |
| prap-2 | Proteus Auto-Parameter v2 |
| prob-2 | Proteus 6-Parameter v2 |
| thd-3 | Theia Fine Tune Detail v3 |
| thf-4 | Theia Fine Tune Fidelity v4 |

#### **Interpolation Models**

|  |  |
| --- | --- |
| apo-8 | Apollo v8 |
| apf-1 | Apollo Fast v1 |
| chr-2 | Chronos v2 |
| chf-1 | Chronos Fast v1 |
| chf-2 | Chronos Fast v2 |
| chf-3 | Chronos Fast v3 |
| chr-1 | Chronos Slo-Mo / FPS Conversion v1 |
| chr-2 | Chronos Slo-Mo / FPS Conversion v2 |

#### **Stabilization Models**

|  |  |
| --- | --- |
| cpe-1 | Camera Pose Estimation (first pass) |
| cpe-2 | Camera Pose Estimation (first pass) + rolling shutter correction |
| ref-2 | Stabilization Model (final pass) |

**Additional Information on the Stabilization Models:** To use the stabilization model, there are two commands that need to be run one after another.

Step 1:

```
./ffmpeg -hide_banner -nostdin -y -i /path/to/input_video -vf tvai_cpe=model=cpe-1:filename=temp/path/cpe.json -f null -
```

Step 2 (Full-Frame):

```
./ffmpeg -hide_banner -nostdin -y -i /path/to/input_video -vf tvai_stb=filename=temp/path/cpe.json:smoothness=6:full=1 path/to/output_video
```

Step 2 (Auto-Crop):

```
./ffmpeg -hide_banner -nostdin -y -i /path/to/input_video -vf tvai_stb=filename=temp/path/cpe.json:smoothness=6:full=0 path/to/output_video
```

## Custom Encoder Options

Topaz Video AI uses ffmpeg to produce output files and apply different encoding settings.

While the graphical menu for export options includes some of the more popular encoders and containers, there is a way to add custom settings that can be used for more advanced workflows.

The video-encoders.json file can be modified to add additional options for encoding. This file is found in the 'models' folder on both Windows and macOS versions of Video AI:

Windows macOS Linux

```
C:\ProgramData\Topaz Labs LLC\Topaz Video AI\models
```

```
/Applications/Topaz Video AI.app/Contents/Resources/models
```

```
/opt/TopazVideoAIBETA/models/
```

As an example of a custom encoder option, we will be updating the "H265 Main10 (NVIDIA)" encoder setting to use the 'slow' preset and B-frame referencing for more efficient compression.

Some of these features are only available on certain GPU models, so it's recommended to research which exact encoder features your specific graphics card supports.

* Copy the preset that most closely matches the custom option you'd like to create
  + In this case, "H265 Main10 (NVIDIA)" will be duplicated directly underneath the original in the video-encoders.json file

```
  {
    "text": "H265 Main10 (NVIDIA) - Slow Preset with B-frame referencing",
    "encoder": "-c:v hevc_nvenc -profile:v main10 -preset slow -pix_fmt p010le -b_ref_mode each -tag:v hvc1",
    "ext": [
      "mov",
      "mkv",
      "mp4"
    ],
    "maxBitRate": 2000,
    "transcode": "aac -b:a 320k -ac 2",
    "os": "windows",
    "device": "nvidia",
    "minSize": [129,129],
    "maxSize": [8192,8192],
    "maxBitDepth": 12
  },
```

In addition to options for the video encoder, this json entry can be edited with a different audio transcode setting, maximum bitrate, bit depth, and OS compatibility to prevent settings being shown on incompatible devices.

It is highly recommended to test any custom video-encoders.json entries with a short video and inspect the result using [MediaInfo](https://mediaarea.net/en/MediaInfo) to ensure that the output matches the expected results.
</file>

<file path="TODO.md">
# TODO

## Core Implementation

- [ ] Set up Python project structure with setup.py and requirements
- [ ] Implement topyazWrapper main class with **init** method
- [ ] Add Python Fire integration for automatic CLI generation
- [ ] Create configuration system with YAML support
- [ ] Implement logging system with multiple output options

## Topaz Integration

- [ ] Implement Video AI integration with FFmpeg wrapper
- [ ] Add environment variable management for TVAI_MODEL_DIR
- [ ] Implement Gigapixel AI CLI wrapper with Pro license detection
- [ ] Add Photo AI integration with Autopilot settings support
- [ ] Create unified parameter mapping between products

## Remote Execution

- [ ] Implement SSH connection management with key-based auth
- [ ] Add macOS native remote execution support
- [ ] Create secure file transfer capabilities
- [ ] Implement remote environment setup and validation

## Error Handling & Validation

- [ ] Add comprehensive input validation for all parameters
- [ ] Implement authentication status checking for all products
- [ ] Create memory and GPU constraint detection
- [ ] Add path validation with space character handling
- [ ] Implement recovery mechanisms for common failures

## Progress Monitoring

- [ ] Create progress tracking for batch operations
- [ ] Add ETA calculation and performance metrics
- [ ] Implement memory usage monitoring
- [ ] Add GPU utilization tracking

## Testing & Quality

- [ ] Write unit tests for all core functionality
- [ ] Add integration tests with mock Topaz executables
- [ ] Create validation scripts for system requirements
- [ ] Implement performance benchmarking tools

## Documentation & Distribution

- [ ] Create comprehensive user documentation
- [ ] Add API documentation with examples
- [ ] Implement interactive setup wizard
- [ ] Package for PyPI distribution

## Advanced Features

- [ ] Add community tool integration (vai-docker, ComfyUI)
- [ ] Implement checkpoint/resume functionality for large batches
- [ ] Create configuration presets for common workflows
- [ ] Add hardware optimization detection
</file>

<file path=".github/workflows/push.yml">
name: Build & Test

on:
  push:
    branches: [main]
    tags-ignore: ["v*"]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Ruff lint
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "check --output-format=github"

      - name: Run Ruff Format
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "format --check --respect-gitignore"

  test:
    name: Run Tests
    needs: quality
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest]
      fail-fast: true
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: ${{ matrix.python-version }}
          enable-cache: true
          cache-suffix: ${{ matrix.os }}-${{ matrix.python-version }}

      - name: Install test dependencies
        run: |
          uv pip install --system --upgrade pip
          uv pip install --system ".[test]"

      - name: Run tests with Pytest
        run: uv run pytest -n auto --maxfail=1 --disable-warnings --cov-report=xml --cov-config=pyproject.toml --cov=src/topyaz --cov=tests tests/

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}-${{ matrix.os }}
          path: coverage.xml

  build:
    name: Build Distribution
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-files
          path: dist/
          retention-days: 5
</file>

<file path=".github/workflows/release.yml">
name: Release

on:
  push:
    tags: ["v*"]

permissions:
  contents: write
  id-token: write

jobs:
  release:
    name: Release to PyPI
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/topyaz
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Verify distribution files
        run: |
          ls -la dist/
          test -n "$(find dist -name '*.whl')" || (echo "Wheel file missing" && exit 1)
          test -n "$(find dist -name '*.tar.gz')" || (echo "Source distribution missing" && exit 1)

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
</file>

<file path="src/topyaz/topyaz.py">
#!/usr/bin/env python3
"""topyaz:

Created by Adam Twardoch
"""

import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

__version__ = "0.1.0"

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


@dataclass
class Config:
    """Configuration settings for topyaz."""

    name: str
    value: str | int | float
    options: dict[str, Any] | None = None


def process_data(data: list[Any], config: Config | None = None, *, debug: bool = False) -> dict[str, Any]:
    """Process the input data according to configuration.

    Args:
        data: Input data to process
        config: Optional configuration settings
        debug: Enable debug mode

    Returns:
        Processed data as a dictionary

    Raises:
        ValueError: If input data is invalid

    """
    if debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("Debug mode enabled")

    if not data:
        msg = "Input data cannot be empty"
        raise ValueError(msg)

    # TODO: Implement data processing logic
    result: dict[str, Any] = {}
    return result


def main() -> None:
    """Main entry point for topyaz."""
    try:
        # Example usage
        config = Config(name="default", value="test", options={"key": "value"})
        result = process_data([], config=config)
        logger.info("Processing completed: %s", result)

    except Exception as e:
        logger.error("An error occurred: %s", str(e))
        raise


if __name__ == "__main__":
    main()
</file>

<file path="tests/test_package.py">
"""Test suite for topyaz."""


def test_version():
    """Verify package exposes version."""
    import topyaz

    assert topyaz.__version__
</file>

<file path=".gitignore">
resources/
*_autogen/
.DS_Store
__version__.py
__pycache__/
_Chutzpah*
_deps
_NCrunch_*
_pkginfo.txt
_Pvt_Extensions
_ReSharper*/
_TeamCity*
_UpgradeReport_Files/
!?*.[Cc]ache/
!.axoCover/settings.json
!.vscode/extensions.json
!.vscode/launch.json
!.vscode/settings.json
!.vscode/tasks.json
!**/[Pp]ackages/build/
!Directory.Build.rsp
.*crunch*.local.xml
.axoCover/*
.builds
.cr/personal
.fake/
.history/
.ionide/
.localhistory/
.mfractor/
.ntvs_analysis.dat
.paket/paket.exe
.sass-cache/
.vs/
.vscode
.vscode/*
.vshistory/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
[Bb]in/
[Bb]uild[Ll]og.*
[Dd]ebug/
[Dd]ebugPS/
[Dd]ebugPublic/
[Ee]xpress/
[Ll]og/
[Ll]ogs/
[Oo]bj/
[Rr]elease/
[Rr]eleasePS/
[Rr]eleases/
[Tt]est[Rr]esult*/
[Ww][Ii][Nn]32/
*_h.h
*_i.c
*_p.c
*_wpftmp.csproj
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl
*- [Bb]ackup.rdl
*.[Cc]ache
*.[Pp]ublish.xml
*.[Rr]e[Ss]harper
*.a
*.app
*.appx
*.appxbundle
*.appxupload
*.aps
*.azurePubxml
*.bim_*.settings
*.bim.layout
*.binlog
*.btm.cs
*.btp.cs
*.build.csdef
*.cab
*.cachefile
*.code-workspace
*.coverage
*.coveragexml
*.d
*.dbmdl
*.dbproj.schemaview
*.dll
*.dotCover
*.DotSettings.user
*.dsp
*.dsw
*.dylib
*.e2e
*.exe
*.gch
*.GhostDoc.xml
*.gpState
*.ilk
*.iobj
*.ipdb
*.jfm
*.jmconfig
*.la
*.lai
*.ldf
*.lib
*.lo
*.log
*.mdf
*.meta
*.mm.*
*.mod
*.msi
*.msix
*.msm
*.msp
*.ncb
*.ndf
*.nuget.props
*.nuget.targets
*.nupkg
*.nvuser
*.o
*.obj
*.odx.cs
*.opendb
*.opensdf
*.opt
*.out
*.pch
*.pdb
*.pfx
*.pgc
*.pgd
*.pidb
*.plg
*.psess
*.publishproj
*.publishsettings
*.pubxml
*.pyc
*.rdl.data
*.rptproj.bak
*.rptproj.rsuser
*.rsp
*.rsuser
*.sap
*.sbr
*.scc
*.sdf
*.sln.docstates
*.sln.iml
*.slo
*.smod
*.snupkg
*.so
*.suo
*.svclog
*.tlb
*.tlh
*.tli
*.tlog
*.tmp
*.tmp_proj
*.tss
*.user
*.userosscache
*.userprefs
*.vbp
*.vbw
*.VC.db
*.VC.VC.opendb
*.VisualState.xml
*.vsp
*.vspscc
*.vspx
*.vssscc
*.xsd.cs
**/[Pp]ackages/*
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.HTMLClient/GeneratedArtifacts
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
*~
~$*
$tf/
AppPackages/
artifacts/
ASALocalRun/
AutoTest.Net/
Backup*/
BenchmarkDotNet.Artifacts/
bld/
BundleArtifacts/
ClientBin/
cmake_install.cmake
CMakeCache.txt
CMakeFiles
CMakeLists.txt.user
CMakeScripts
CMakeUserPresets.json
compile_commands.json
coverage*.info
coverage*.json
coverage*.xml
csx/
CTestTestfile.cmake
dlldata.c
DocProject/buildhelp/
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/*.HxC
DocProject/Help/*.HxT
DocProject/Help/html
DocProject/Help/Html2
ecf/
FakesAssemblies/
FodyWeavers.xsd
Generated_Code/
Generated\ Files/
healthchecksdb
install_manifest.txt
ipch/
Makefile
MigrationBackup/
mono_crash.*
nCrunchTemp_*
node_modules/
nunit-*.xml
OpenCover/
orleans.codegen.cs
Package.StoreAssociation.xml
paket-files/
project.fragment.lock.json
project.lock.json
publish/
PublishScripts/
rcf/
ScaffoldingReadMe.txt
ServiceFabricBackup/
StyleCopReport.xml
Testing
TestResult.xml
UpgradeLog*.htm
UpgradeLog*.XML
x64/
x86/
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Distribution / packaging
!dist/.gitkeep

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/
.ruff_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
__version__.py
_private
VERSION.txt
</file>

<file path=".pre-commit-config.yaml">
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.3.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
        args: [--respect-gitignore]
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: check-yaml
      - id: check-toml
      - id: check-added-large-files
      - id: debug-statements
      - id: check-case-conflict
      - id: mixed-line-ending
        args: [--fix=lf]
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Adam Twardoch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="package.toml">
# Package configuration
[package]
include_cli = true        # Include CLI boilerplate
include_logging = true    # Include logging setup
use_pydantic = true      # Use Pydantic for data validation
use_rich = true          # Use Rich for terminal output

[features]
mkdocs = false           # Enable MkDocs documentation
vcs = true              # Initialize Git repository
github_actions = true   # Add GitHub Actions workflows
</file>

<file path="pyproject.toml">
# this_file: pyproject.toml
#==============================================================================
# TOPYAZ PACKAGE CONFIGURATION
# This pyproject.toml defines the package metadata, dependencies, build system,
# and development environment for the topyaz package.
#==============================================================================

#------------------------------------------------------------------------------
# PROJECT METADATA
# Core package information used by PyPI and package managers.
#------------------------------------------------------------------------------
[project]
name = 'topyaz' # Package name on PyPI
description = '' # Short description
readme = 'README.md' # Path to README file
requires-python = '>=3.10' # Minimum Python version
keywords = [
] # Keywords for PyPI search
dynamic = ["version"] # Fields set dynamically at build time

# PyPI classifiers for package categorization
classifiers = [
    'Development Status :: 4 - Beta', # Package maturity level
    'Programming Language :: Python',
    'Programming Language :: Python :: 3.10',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: Implementation :: CPython',
    'Programming Language :: Python :: Implementation :: PyPy',
    'Operating System :: OS Independent',
    'License :: OSI Approved :: MIT License',
    'Intended Audience :: Developers',
]

dependencies = [
]

# Author information
[[project.authors]]
name = 'Adam Twardoch'
email = 'adam+github@twardoch.com'

# License information
[project.license]
text = 'MIT'

# Project URLs
[project.urls]
Documentation = 'https://github.com/twardoch/topyaz#readme'
Issues = 'https://github.com/twardoch/topyaz/issues'
Source = 'https://github.com/twardoch/topyaz'

#------------------------------------------------------------------------------
# OPTIONAL DEPENDENCIES
# Additional dependencies for optional features, development, and testing.
#------------------------------------------------------------------------------
[project.optional-dependencies]

# Development tools
dev = [
    'pre-commit>=4.1.0', # Pre-commit hook manager - Keep pre-commit as is, update if newer pre-commit version is required
    'ruff>=0.9.7', # Linting and formatting - Keep ruff as is, update if newer ruff version is required
    'mypy>=1.15.0', # Type checking - Keep mypy as is, update if newer mypy version is required
    'absolufy-imports>=0.3.1', # Convert relative imports to absolute - Keep absolufy-imports as is, update if newer absolufy-imports version is required
    'pyupgrade>=3.19.1', # Upgrade Python syntax - Keep pyupgrade as is, update if newer pyupgrade version is required
    'isort>=6.0.1', # Sort imports - Keep isort as is, update if newer isort version is required
]

# Testing tools and frameworks
test = [
    'pytest>=8.3.4', # Testing framework - Keep pytest as is, update if newer pytest version is required
    'pytest-cov>=6.0.0', # Coverage plugin for pytest - Keep pytest-cov as is, update if newer pytest-cov version is required
    'pytest-xdist>=3.6.1', # Parallel test execution - Keep pytest-xdist as is, update if newer pytest-xdist version is required
    'pytest-benchmark[histogram]>=5.1.0', # Benchmarking plugin - Keep pytest-benchmark as is, update if newer pytest-benchmark version is required
    'pytest-asyncio>=0.25.3', # Async test support - Keep pytest-asyncio as is, update if newer pytest-asyncio version is required
    'coverage[toml]>=7.6.12',
]

docs = [
    "sphinx>=7.2.6",
    "sphinx-rtd-theme>=2.0.0",
    "sphinx-autodoc-typehints>=2.0.0",
    "myst-parser>=3.0.0", # Markdown support in Sphinx
]

# All optional dependencies combined
all = [
]

#------------------------------------------------------------------------------
# COMMAND-LINE SCRIPTS
# Entry points for command-line executables installed with the package.
#------------------------------------------------------------------------------
[project.scripts]
# CLINAME = "topyaz.__main__:main"

#------------------------------------------------------------------------------
# BUILD SYSTEM CONFIGURATION
# Defines the tools required to build the package and the build backend.
#------------------------------------------------------------------------------
[build-system]
# Hatchling is a modern build backend for Python packaging
# hatch-vcs integrates with version control systems for versioning
requires = [
    'hatchling>=1.27.0', # Keep hatchling as is, update if newer hatchling version is required
    'hatch-vcs>=0.4.0', # Keep hatch-vcs as is, update if newer hatch-vcs version is required
]
build-backend = 'hatchling.build' # Specifies Hatchling as the build backend


#------------------------------------------------------------------------------
# HATCH BUILD CONFIGURATION
# Configures the build process, specifying which packages to include and
# how to handle versioning.
#------------------------------------------------------------------------------
[tool.hatch.build]
# Include package data files
include = [
    "src/topyaz/py.typed", # For better type checking support
    "src/topyaz/data/**/*", # Include data files if any

]
exclude = ["**/__pycache__", "**/.pytest_cache", "**/.mypy_cache"]

[tool.hatch.build.targets.wheel]
packages = ["src/topyaz"]
reproducible = true


# Version control system hook configuration
# Automatically updates the version file from git tags
[tool.hatch.build.hooks.vcs]
version-file = "src/topyaz/__version__.py"

# Version source configuration
[tool.hatch.version]
source = 'vcs' # Get version from git tags or other VCS info

# Metadata handling configuration
[tool.hatch.metadata]
allow-direct-references = true # Allow direct references in metadata (useful for local dependencies)


#------------------------------------------------------------------------------
# DEVELOPMENT ENVIRONMENTS

[tool.hatch.envs.default]
features = ['dev', 'test', 'all']
dependencies = [
]

# Commands available in the default environment
[tool.hatch.envs.default.scripts]
# Run tests with optional arguments
test = 'pytest {args:tests}'
# Run tests with coverage reporting
test-cov = "pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/topyaz --cov=tests {args:tests}"
# Run type checking
type-check = "mypy src/topyaz tests"
# Run linting and formatting
lint = ["ruff check src/topyaz tests", "ruff format --respect-gitignore src/topyaz tests"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore src/topyaz tests", "ruff check --fix src/topyaz tests"]
fix = ["ruff check --fix --unsafe-fixes src/topyaz tests", "ruff format --respect-gitignore src/topyaz tests"]

# Matrix configuration to test across multiple Python versions

[[tool.hatch.envs.all.matrix]]
python = ["3.10", "3.11", "3.12"]

#------------------------------------------------------------------------------
# SPECIALIZED ENVIRONMENTS
# Additional environments for specific development tasks.
#------------------------------------------------------------------------------

# Dedicated environment for linting and code quality checks
[tool.hatch.envs.lint]
detached = true # Create a separate, isolated environment
features = ['dev'] # Use dev extras  dependencies 

# Linting environment commands
[tool.hatch.envs.lint.scripts]
# Type checking with automatic type installation
typing = "mypy --install-types --non-interactive {args:src/topyaz tests}"
# Check style and format code
style = ["ruff check {args:.}", "ruff format --respect-gitignore {args:.}"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore {args:.}", "ruff check --fix {args:.}"]
fix = ["ruff check --fix --unsafe-fixes {args:.}", "ruff format --respect-gitignore {args:.}"]
# Run all ops
all = ["style", "typing", "fix"]

# Dedicated environment for testing
[tool.hatch.envs.test]
features = ['test'] # Use test extras as dependencies

# Testing environment commands
[tool.hatch.envs.test.scripts]
# Run tests in parallel
test = "python -m pytest -n auto {args:tests}"
# Run tests with coverage in parallel
test-cov = "python -m pytest -n auto --cov-report=term-missing --cov-config=pyproject.toml --cov=src/topyaz --cov=tests {args:tests}"
# Run benchmarks
bench = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only"
# Run benchmarks and save results
bench-save = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json"

# Documentation environment
[tool.hatch.envs.docs]
features = ['docs']

# Documentation environment commands
[tool.hatch.envs.docs.scripts]
build = "sphinx-build -b html docs/source docs/build"

# GitHub Actions workflow configuration
[tool.hatch.envs.ci]
features = ['test']


[tool.hatch.envs.ci.scripts]
test = "pytest --cov=src/topyaz --cov-report=xml"


#------------------------------------------------------------------------------
# CODE QUALITY TOOLS
# Configuration for linting, formatting, and code quality enforcement.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# COVERAGE CONFIGURATION
# Settings for test coverage measurement and reporting.
#------------------------------------------------------------------------------

# Path mapping for coverage in different environments
[tool.coverage.paths]
topyaz = ["src/topyaz", "*/topyaz/src/topyaz"]
tests = ["tests", "*/topyaz/tests"]

# Coverage report configuration
[tool.coverage.report]
# Lines to exclude from coverage reporting
exclude_lines = [
    'no cov', # Custom marker to skip coverage
    'if __name__ == .__main__.:', # Script execution guard
    'if TYPE_CHECKING:', # Type checking imports and code
    'pass', # Empty pass statements
    'raise NotImplementedError', # Unimplemented method placeholders
    'raise ImportError', # Import error handling
    'except ImportError', # Import error handling
    'except KeyError', # Common error handling
    'except AttributeError', # Common error handling
    'except NotImplementedError', # Common error handling
]

[tool.coverage.run]
source_pkgs = ["topyaz", "tests"]
branch = true # Measure branch coverage (if/else statements)
parallel = true # Support parallel test execution
omit = [
    "src/topyaz/__about__.py",
]

#------------------------------------------------------------------------------
# MYPY CONFIGURATION
# Configuration for type checking with mypy.
#------------------------------------------------------------------------------

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ["tests.*"]
disallow_untyped_defs = false
disallow_incomplete_defs = false

#------------------------------------------------------------------------------
# PYTEST CONFIGURATION
# Configuration for pytest, including markers, options, and benchmark settings.
#------------------------------------------------------------------------------

[tool.pytest.ini_options]
addopts = "-v --durations=10 -p no:briefcase"
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
console_output_style = "progress"
filterwarnings = ["ignore::DeprecationWarning", "ignore::UserWarning"]
log_cli = true
log_cli_level = "INFO"
markers = [
    "benchmark: marks tests as benchmarks (select with '-m benchmark')",
    "unit: mark a test as a unit test",
    "integration: mark a test as an integration test",
    "permutation: tests for permutation functionality", 
    "parameter: tests for parameter parsing",
    "prompt: tests for prompt parsing",
]
norecursedirs = [
    ".*",
    "build",
    "dist", 
    "venv",
    "__pycache__",
    "*.egg-info",
    "_private",
]
python_classes = ["Test*"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
testpaths = ["tests"]

[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = "file"
save-data = true
compare = [
    "min",    # Minimum time
    "max",    # Maximum time
    "mean",   # Mean time
    "stddev", # Standard deviation
    "median", # Median time
    "iqr",    # Inter-quartile range
    "ops",    # Operations per second
    "rounds", # Number of rounds
]

#------------------------------------------------------------------------------
# RUFF CONFIGURATION
# Configuration for Ruff, including linter and formatter settings.
#------------------------------------------------------------------------------ 

# Ruff linter and formatter configuration
[tool.ruff]
target-version = "py310"
line-length = 120

# Linting rules configuration
[tool.ruff.lint]
# Rule sets to enable, organized by category
select = [
    # flake8 plugins and extensions
    'A', # flake8-builtins: checks for shadowed builtins
    'ARG', # flake8-unused-arguments: checks for unused function arguments
    'ASYNC', # flake8-async: checks for async/await issues
    'B', # flake8-bugbear: finds likely bugs and design problems
    'C', # flake8-comprehensions: helps write better list/dict comprehensions
    'DTZ', # flake8-datetimez: checks for datetime timezone issues
    'E', # pycodestyle errors: PEP 8 style guide errors
    'EM', # flake8-errmsg: checks for better error messages
    'F', # pyflakes: detects various errors
    'FBT', # flake8-boolean-trap: checks for boolean traps in function signatures
    'I', # isort: sorts imports
    'ICN', # flake8-import-conventions: checks for import conventions
    'ISC', # flake8-implicit-str-concat: checks for implicit string concatenation
    'LOG', # flake8-logging: checks for logging issues
    'N', # pep8-naming: checks naming conventions
    'PLC', # pylint convention: checks for convention issues
    'PLE', # pylint error: checks for errors
    'PLR', # pylint refactor: suggests refactors
    'PLW', # pylint warning: checks for suspicious code
    'PT', # flake8-pytest-style: checks pytest-specific style
    'PTH', # flake8-use-pathlib: checks for stdlib path usage vs pathlib
    'PYI', # flake8-pyi: checks stub files
    'RET', # flake8-return: checks return statement consistency
    'RSE', # flake8-raise: checks raise statements
    'RUF', # Ruff-specific rules
    'S', # flake8-bandit: checks for security issues
    'SIM', # flake8-simplify: checks for code simplification opportunities
    'T', # flake8-print: checks for print statements
    'TCH', # flake8-type-checking: helps with type-checking
    'TID', # flake8-tidy-imports: checks for tidy import statements
    'UP', # pyupgrade: checks for opportunities to use newer Python features
    'W', # pycodestyle warnings: PEP 8 style guide warnings
    'YTT', # flake8-2020: checks for misuse of sys.version or sys.version_info

]
# Rules to ignore (with reasons)
ignore = [
    'B027', # Empty method in abstract base class - sometimes needed for interfaces
    'C901', # Function is too complex - sometimes complexity is necessary
    'FBT003', # Boolean positional argument in function definition - sometimes unavoidable
    'PLR0911', # Too many return statements - sometimes needed for readability
    'PLR0912', # Too many branches - sometimes needed for complex logic
    'PLR0913', # Too many arguments - sometimes needed in APIs
    'PLR0915', # Too many statements - sometimes needed for comprehensive functions
    'PLR1714', # Consider merging multiple comparisons - sometimes less readable
    'PLW0603', # Using the global statement - sometimes necessary
    'PT013', # Pytest explicit test parameter - sometimes clearer
    'PTH123', # Path traversal - sometimes needed
    'PYI056', # Calling open() in pyi file - sometimes needed in type stubs
    'S105', # Possible hardcoded password - often false positives
    'S106', # Possible hardcoded password - often false positives
    'S107', # Possible hardcoded password - often false positives
    'S110', # try-except-pass - sometimes valid for suppressing exceptions
    'SIM102'
    # Nested if statements - sometimes more readable than combined conditions
]
# Rules that should not be automatically fixed
unfixable = [
    'F401', # Don't automatically remove unused imports - may be needed later

]
# Configure exclude to ignore specific directories
exclude = [".git", ".venv", "venv", "dist", "build"]

# isort configuration within Ruff
[tool.ruff.lint.isort]
known-first-party = ['topyaz'] # Treat as first-party imports for sorting

# flake8-tidy-imports configuration within Ruff
[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = 'all' # Ban all relative imports for consistency

# Per-file rule exceptions
[tool.ruff.lint.per-file-ignores]
# Tests can use magic values, assertions, and relative imports
'tests/**/*' = [
    'PLR2004', # Allow magic values in tests for readability
    'S101', # Allow assertions in tests
    'TID252'
    # Allow relative imports in tests for convenience
]
</file>

<file path="README.md">
# topyaz: Unified CLI Wrapper for Topaz Labs Products

A comprehensive Python package that provides a unified command-line interface for Topaz Labs' Video AI, Gigapixel AI, and Photo AI products. Built for professionals who need robust batch processing, remote execution, and automated workflows.

## ✨ Features

- **🎯 Unified Interface**: Single command-line tool for all three Topaz products
- **🌐 Remote Execution**: Run processing on remote machines via SSH
- **🔄 Batch Processing**: Intelligent batch operations with progress monitoring
- **🛡️ Failsafe Design**: Comprehensive error handling and recovery mechanisms
- **📊 Progress Tracking**: Real-time progress with ETA calculations
- **⚙️ Hardware Optimization**: Automatic detection and optimization for your system
- **🔧 Flexible Configuration**: YAML-based configuration with preset workflows

## 🚀 Quick Start

### Installation

```bash
pip install topyaz
```

### Basic Usage

```bash
# Upscale a video using Video AI
topyaz video input.mp4 --scale 2 --model amq-13

# Batch upscale images with Gigapixel AI (Pro license required)
topyaz gp photos/ --scale 4 --model recovery --denoise 40

# Enhance photos with Photo AI Autopilot
topyaz photo raw_photos/ --format jpg --quality 95

# Remote processing on a powerful machine
topyaz video large_video.mp4 --remote-host gpu-server --scale 4
```

## 📋 Requirements

### System Requirements
- **macOS**: 11.0 Big Sur or higher
  - macOS 13 Ventura+ for advanced Video AI models (Rhea, Aion)
  - macOS 14 Sonoma+ for Gigapixel AI generative models
- **Python**: 3.8 or higher
- **Memory**: 16GB RAM minimum (32GB recommended for 4K video)
- **Storage**: 80GB+ free space for Video AI models
- **GPU**: 2GB+ VRAM for GPU acceleration

### Topaz Products
- **Topaz Video AI**: Any valid license
- **Topaz Gigapixel AI**: Pro license required for CLI access ($499/year)
- **Topaz Photo AI**: Any valid license

## 🔧 Configuration

Create a configuration file at `~/.topyaz/config.yaml`:

```yaml
defaults:
  output_dir: "~/processed"
  preserve_structure: true
  backup_originals: false
  log_level: "INFO"

video:
  default_model: "amq-13"
  default_codec: "hevc_videotoolbox"
  default_quality: 18

gigapixel:
  default_model: "std"
  default_format: "preserve"
  parallel_read: 4

photo:
  default_format: "jpg"
  default_quality: 95

remote_hosts:
  gpu-server:
    host: "192.168.1.100"
    user: "admin"
    key: "~/.ssh/topaz_key"
```

## 📖 Documentation

### Video AI Processing

```bash
# Basic upscaling
topyaz video input.mp4 --scale 2 --model amq-13

# Advanced processing with stabilization and interpolation
topyaz video shaky_video.mp4 \
    --stabilize \
    --scale 2 \
    --interpolate \
    --fps 60 \
    --denoise 50

# Batch processing with custom output
topyaz video videos/ \
    --scale 2 \
    --model prob-3 \
    --output-dir ./enhanced \
    --recursive
```

**Supported Models:**
- **Artemis**: amq-13, ahq-10/11/12, alq-10/12/13, alqs-1/2, amqs-1/2, aaa-9/10
- **Proteus**: prob-2, prap-2
- **Dione**: ddv-1/2/3, dtd-1/3/4, dtds-1/2, dtv-1/3/4, dtvs-1/2
- **Gaia**: gcg-5, ghq-5
- **Theia**: thd-3, thf-4
- **Interpolation**: chr-1/2, chf-1/2/3, apo-8, apf-1

### Gigapixel AI Processing

```bash
# Standard upscaling
topyaz gp images/ --scale 4 --model std

# Art & CG optimization
topyaz gp artwork/ --scale 2 --model art --sharpen 30

# Generative upscaling with prompts
topyaz gp photos/ \
    --model redefine \
    --scale 2 \
    --creativity 4 \
    --texture 3 \
    --prompt "high resolution portrait photography"

# Face recovery enhancement
topyaz gp portraits/ \
    --scale 2 \
    --model recovery \
    --face-recovery 80 \
    --face-recovery-creativity 1
```

**Available Models:**
- **Standard**: std, hf (high fidelity), low (low resolution)
- **Specialized**: art/cg (Art & CG), lines, text, vc (very compressed)
- **Recovery**: recovery (with face enhancement)
- **Generative**: redefine (with AI prompts)

### Photo AI Processing

```bash
# Autopilot enhancement
topyaz photo raw_photos/ --format jpg --quality 95

# Custom format conversion
topyaz photo images/ \
    --format tiff \
    --bit-depth 16 \
    --tiff-compression zip

# Show current Autopilot settings
topyaz photo test_image.jpg --show-settings --skip-processing
```

### Remote Execution

```bash
# Process on remote machine
topyaz video large_file.mp4 \
    --remote-host gpu-server \
    --ssh-user processor \
    --ssh-key ~/.ssh/render_key \
    --scale 4

# Distributed processing across multiple machines
topyaz gp large_collection/ \
    --remote-host server1,server2,server3 \
    --parallel-jobs 3 \
    --load-balance
```

## 🔍 Troubleshooting

### Common Issues

**"No such filter: tvai_up" Error**
```bash
# Check Video AI installation
topyaz validate --check-video-ai

# Verify environment variables
topyaz diagnose --show-env
```

**Authentication Failures**
```bash
# Re-authenticate with Topaz products
topyaz setup --verify-licenses

# Check Pro license for Gigapixel AI
topyaz validate --check-gigapixel-pro
```

**Memory Issues**
```bash
# Process with smaller batches
topyaz video large_video.mp4 --scale 2 --segment-size 60

# Monitor memory usage
topyaz profile --memory --operation video
```

### Diagnostic Tools

```bash
# System diagnostic report
topyaz diagnose --full-report

# Performance benchmark
topyaz benchmark --test-local --test-remote

# Validate system requirements
topyaz validate --check-all
```

## 🤝 Community Integration

topyaz integrates with popular community tools:

- **[vai-docker](https://github.com/jojje/vai-docker)**: Docker containerization for Video AI
- **[ComfyUI-TopazVideoAI](https://github.com/sh570655308/ComfyUI-TopazVideoAI)**: ComfyUI workflow integration
- **[gigapixel-automator](https://github.com/halfSpinDoctor/gigapixel-automator)**: Legacy AppleScript automation

## 📊 Performance

Performance benchmarks on Apple M3 Max (128GB RAM):

| Operation | Files | Size | Time | Speed |
|-----------|-------|------|------|-------|
| Video AI 2x | 10 videos | 50GB | 45 min | ~2x faster than GUI |
| Gigapixel 4x | 100 images | 5GB | 16 min | ~2x faster than GUI |
| Photo AI batch | 500 images | 10GB | 8 min | ~1.5x faster than GUI |

## 🔒 Security

- SSH key-based authentication only
- No password storage or transmission
- Secure file transfer protocols
- Command injection prevention
- Audit logging for all operations

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- [Topaz Labs](https://www.topazlabs.com/) for their excellent AI-powered tools
- Community contributors and tool developers
- Beta testers and early adopters

## 📞 Support

- **Documentation**: [docs.topyaz.org](https://docs.topyaz.org)
- **Issues**: [GitHub Issues](https://github.com/username/topyaz/issues)
- **Discussions**: [GitHub Discussions](https://github.com/username/topyaz/discussions)
- **Community**: [Topaz Labs Community](https://community.topazlabs.com/)

---

**Note**: This project is not officially affiliated with Topaz Labs. It's a community-driven wrapper around their CLI tools.
</file>

</files>
